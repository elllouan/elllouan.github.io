<!DOCTYPE html>

<html lang ="en">

    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- make sure that the content fit the device on which we open -->
        <title> School </title>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Audiowide|Sofia|Trirong|Arial|Open+Sans">
        <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
        <script src="js/script.js"></script>
        <link rel="stylesheet" href="generic-patterns/css/main.css">
        <link rel="stylesheet" href="generic-patterns/css/horizontalmenu.css">
        <link rel="stylesheet" href="generic-patterns/css/footer.css">
        <link rel="stylesheet" href="css/school.css">
    </head>

    <!-- Within de web page -->
    <body>
        <div id="horizontalmenu"></div>
        
        <section class="main-container">

            <a href="https://www.enib.fr/fr/" class="enib-link"><img src="images/enib.webp" class="enib-logo"></a>

            <section class="accordion-y4">

                <h1 class="title">4th year of engineering studies</h1>
                <p>In this section, I try to provide an overview of my learning outcomes by presenting the most relevant parts of each course. 
                    To have a broader view of each course's content, you can expand their section by clicking on their title.</p>
                
                <div class="subject-container"> <div class="label"> <h2>Signal Processing</h2> </div>
                    <div class="keywords">Convolution systems, FIR & IIR filters, distorsion, correlation, Butterworth & Chebychev, Laplace/Fourier transforms, Analog/Discrete signals, modulation, Matlab</div>
                    <div class="content">
                        <p>The following content gives an overview of the digital/analog signal processing courses that I followed at my school. This is not meant to be a comprhensive description but rather a brief guide.</p>
                        <hr>
                        <div class="subject-subdiv"> <h3>1. Convolution</h3>
                            <p>In linear filtering, convolution plays a fundamental role. Indeed, if we write a signal \(x(t)\) such that \(x(t) = \int^{+\infty}_{-\infty} x(\tau)\delta(t-\tau) d\tau \),
                                with \( \delta(t) \) the Dirac impulse. Then when applying the filter function on the signal, we have :
                                \[ f(x) = \int^{+\infty}_{-\infty} f(x(\tau)\delta(t-\tau)) d\tau \]
                                \[ f(x) = \int^{+\infty}_{-\infty} x(\tau)f(\delta(t-\tau)) d\tau,\ (linearity\ property) \]
                                \[ y(t) = \int^{+\infty}_{-\infty} x(\tau) h((t-\tau)) d\tau, (time-independent\ property) \]
                                \( h(t) \) represents the output function when we input the Dirac impulse into the filter and \( y(t) \) is the signal \( x(t) \) filtered.
                                We end up on the convolution operation between the input signal and the Dirac impulse output function.
                            </p>
                        </div>
                        <hr>
                        <div class="subject-subdiv"> <h3>2. Physical limitations and signal reconstitution</h3>
                            <p>To simplify calculations, physicians invented this mathematical object called Dirac impulse. Unfortunately, in the real world we cannot recreate this impulse.
                                Indeed, transistors have a toggle limitation due to the speed of current, causing a Dirac impulse to look like more of a brief door function.
                                But what does this actually involve for a signal? Because to sample a continuous signal, we need to use this theorical object. Does this inaccuracy cause the signal to transform?
                                
                            </p>
                        </div>
                        <hr>
                        <div class="subject-subdiv"> <h3>3. Discrete Fourier Transform (DFT) and Analog Filter Synthesis</h3>
                            <p>This course gives an understanding on how we numerize a signal, what are the impacts and how we can elaborate a digital filter to filter an analog signal.</p>
                            <p>With a view to processing digital signals, we need to turn a continuous (or analog) signal into a discrete signal
                                that consists of a finite number of samples that can be handled by a processor. Therefore, we use the DFT, let's remind us quickly of that. </p>
                            <div class="frame-highlight">
                                <ol>
                                    <li> <span class="bold">Sampling & Quantification:</span>            turns the continuous signal into a discrete signal.</li>
                                    <li> <span class="bold">Temporal truncation of the signal:</span>    get an finite amount of samplings.</li>
                                    <li> <span class="bold">Spectral discretization:</span>              turns the continuous spectrum into a discrete spectrum.</li>
                                    <li> <span class="bold">Zero-Padding (optional):</span>              increase the spectrum's resolution.</li>
                                </ol>
                            </div>
                            <p>However, each one of these steps has an impact on the signal. Indeed, discretizing a signal is not without consequences and some parameters should be chosen wisely
                                to avoid aliasing and other artifacts.
                            </p>
                            <button id="tsi-graphs1">Show illustrations</button>
                        </div>
                        <hr>
                        <div class="subject-subdiv"> <h3>4. Digital Filter Synthesis</h3>
                            <p>There exists 2 types of digital filters: <span class="mark">IIR (Infinite Impulse Response)</span> and <span class="mark">FIR (Finite Impulse Response)</span>.</p>
                            <div class="frame-highlight">
                            <span class="mark">IIR:</span> the output depends on the current and previous inputs and outputs <span class="math">\( s[n] = \sum_{i=0}^{M-1}{a_i e[i]} + \sum_{j=0}^{N-1}{a_i s[n-i]} \)</span>
                                    <p>The purpose of this method is to determine the equivalent digital form \( H(z) \) (\(z\)-domain) of the analog template filter \( H(p) \). From there, we can deduce the <span class="bold">recursive algorithm \( s[n] \)</span> 
                                        that will implement the digital filter.
                                        This method is <span class="bold">more accurate</span> and will be generally preferred over the RIF method. However, the analog reference filter must meet some stability criteria (poles on the left half part of the complex plane).</p>
                                    <p> - <span class="bold">Invariance of the Impulse Response:</span> This method consists of starting with a digital filter template and then switch to an analog template by considering that \( \omega_n = \omega_a \).
                                        Then we figure out the analog filter's transfer function (analog poles \(p)\) and we match back this analog filter with the correspondong digital filter. </p>
                                    </p>
                                    <p> - <span class="bold">Bilinear transform:</span> This method consists of the same approach as the previous one expects we consider that digital pulsations are transformed to analog pulsations by the following relation:
                                        \( \omega_a = \frac{2}{T_e} tan(\frac{\omega_n T_e}{2}) \). This relation comes from this approximation: \( p \equiv \frac{2}{T_e}\frac{(1-z^{-1})}{(1+z^{-1})} \).
                                        <img src="images/bilinear.svg" alt="bilinear">
                                    </p>
                                    <p>All in all, this method has some benefits - <span class="bold">more selective, faster and requires fewer memory registers</span> - and some drawbacks - <span class="bold">can be unstable (poles), non-linear phase</span>.</p>
                            </div>
                            <div class="frame-highlight">
                                <span class="mark">FIR:</span> the output depends only on the current and previous inputs > <span class="math">\( s[n] = \sum_{i=0}^{N-1}{a_i e[i] h[n-i]} \)</span>
                                <p>The purpose of this method is to determine an <span class="bold">approximation of the filter's impulse response</span> and then convolute it with the input signal.
                                    As we consider only an approximation, the <span class="bold">filter's characteristics get modified</span> and we have to deal with some drawbacks such as the 
                                    <span class="bold">apparition of wavelets</span> in the filter's spectrum (caused by the truncation --> convolution with sinc).</p>
                                <p> - <span class="bold">Coherence of the Impulse Response:</span></p>
                                    <ol>
                                        <li>Sampling frequency: Determine \( f_{max}\) and apply the Shannon theorem: \(f_e\ \geq\ 2f_{max}\)</li>
                                        <li>Impulse response (IR): Find the impulse response of the analog filter.</li>
                                        <li>Signal truncation: Truncate the IR after a rank N such that \( h(N) \geq \frac{h_{max}}{100}\)</li>
                                    </ol>
                                <p> - <span class="bold">Discretization of the inverse DFT:</span> We determine the IR samples using direclty the inverse DFT definition > <span class="math">\( h[n] = \frac{1}{N} \sum_{k=-\frac{N}{2}}^{\frac{N}{2}-1} X(k\delta f) e^{j2\pi \frac{n}{N}k} \)</span>.</p>
                                <p>All in all, this method has some benefits - <span class="bold">always stable (no poles), linear phase (if symmetric)</span> - and some drawbacks - <span class="bold">less selective, less efficient and requires more memory space</span>.</p>
                            </div>
                        </div>
                        <hr>
                        <div class="subject-subdiv"> <h3>5. Signal modulation</h3>
                            <p>When it comes to transmitting information using signals, we face some issues:</p>
                            <div class="frame-highlight">
                                <ol>
                                    <li>most of the time the signal transmitted is comprised within a range of 20 to 20kHz (voice frequency), thus if we transmit the signal at its original frequency, we would end up having all signals interfering with each other (all the same frequency)</li>
                                    <li>the size of the receiver should also be ridiculously large for detecting such signals (several kilometers)</li>
                                </ol>
                            </div>
                            <p>Modulation allows to slide the signal spectrum along the frequency axis to a higher frequency, thereby countering the two previous problems. Indeed, we can control the frequency at which we want our signal to be broadcasted, thereby
                                <span class="mark">reducing significantly the size of the receiver</span> and also <span class="mark">avoiding signal overlapping</span>.</p>
                            <p>In the following schema, \(x(t)\) is the signal to be transmitted (carrier signal), \(s(t)\) is the signal modulated and emitted,
                                \(m(t)\) is the modulation signal, \(d(t)\) is the demodulation signal and \(y(t)\) is ideally the same as \(x(t)\).
                            </p>
                            <img class="modulation-img" src="images/modulation.drawio.png" alt="mod">
                        </div>
                        <hr>
                        <div class="subject-subdiv"> <h3>6. Intercorrelation</h3>
                            <p>The correlation method is in the field of radar. When emitting a signal, we want to be able to detect if the signal comes back to us (obstacle detection for instance).
                                Thus, the detector needs to constantly compare any received signal to with the one that was originally emitted.
                            </p>
                            <div class="frame-highlight">
                            <ol>
                                <li>most of the time the signal transmitted is comprised within a range of 20 to 20kHz (voice frequency), thus if we transmit the signal at its original frequency, we would end up having all signals interfering with each other (all the same frequency)</li>
                                <li>the size of the receiver should also be ridiculously large for detecting such signals (several kilometers)</li>
                            </ol>
                            <p>Modulation allows to slide the signal spectrum along the frequency axis to a higher frequency, thereby countering the two previous problems because now we can control the frequency at which we want our signal to be broadcasted and as the frequency gets higher, the receiver gets smaller.</p>
                            </div>
                        </div>
                        <hr>
                        <div class="subject-subdiv"> <h3>7. Further discussions</h3>
                        </div>
                    </div>
                </div>
               
                <div class="subject-container"> <div class="label"> <h2>Image Processing</h2> </div>
                    <div class="keywords">Image representation and acquisition, image segmentation, filtering, image classification and recognition, CNN, Matlab, OpenCV</div>
                    <div class="content">
                        <p>You can find out some of my personal experiments regarding image filtering and processing <a href="">here</a>. Also, you will find at the end of this page,
                            some useful Matlab and OpenCV examples. 
                        </p>
                        <hr>
                        <div class="subject-subdiv"> <h3>1. Introduction</h3>
                            <p>Image processing encompasses several steps from image filtering to classification. The ultimate purpose is to train a machine to recognize patterns on an image
                                in order to automate image analysis. It is important to note that, we increase the dimension by one (regarding signal processing) and we do not deal with the time coordonate \(t\) anymore
                                but with spatial coordonates represented by \(x\) and \(y\).
                            </p>
                        </div>
                        <hr>
                        <div class="subject-subdiv"> <h3>2. Textures</h3>
                            <p>In this section, we focus on how to classify textures. Textures are hard to define as they highly depend on the context. The purpose here is to be able to detect 
                                 and classify textures by identifying patterns. To do so, we can use two approaches: <span class="bold">statistical</span> or <span class="bold">spectral</span>.
                            </p>
                            <div> <h4>Spectral approach</h4>
                                <p>The <span class="bold">spectral</span> approach consists of computing the Fourier transform of the image. Now, let me introduce the Fourier transform of a 2D signal.
                                    \[ I(u,v) = \int^{+\infty}_{-\infty}\int^{+\infty}_{-\infty} I(x,y) e^{-j2\pi(ux+vy)} dxdy \]
                                    The result \( I(u,v) \) is the description of the image in the frequency domain, where \(u\) and \(v\) represent respectively the frequency along the \(x\) and \(y\) axis.
                                    Below, I show examples of images Fourier transform. Each point on the spectrum has an intensity which represents the contribution of each frequency along the x-axis and y-axis.
                                    This approach is useful to detect periodic textures. For example in the first spectrum, we notice 2 small disks in a diagonal which means that the image is likely to have a diagonal periodicity in this direction.
                                    In the second spectrum, we notice a circle which means that the image is likely to have a circular periodicity.
                                </p>
                                <div class="illustration-horiz">
                                    <img src="images/ai/tf_img1.PNG" alt="">
                                    <img src="images/ai/tf_img2.PNG" alt="">
                                    <img src="images/ai/tf_img3.PNG" alt="">
                                </div>
                                <p>With this approach, we only seek to modify the image's module (in the frequency domain). Indeed, modifying the module results in changing the looking of objects (contrast, luminosity, etc.)
                                    but <span class="bold">NOT the shapes themselves</span>, which are encoded in the phase.
                                    \[ I(u,v) = |I(u,v)| e^{j\phi(u,v)} \]
                                </p>
                            </div>
                            <div> <h4>Gabor filters</h4>
                                <p>There are also <span class="bold">Gabor filters</span> that are used to detect orientations in an image. They are <span class="bold">band-pass filters</span> and operate a linear filtering on the image
                                    to extract information about the frequency and the orientation. They are defined by the following equation:
                                    \[ G(x,y) = e^{-\frac{x^2+\gamma^2 y^2}{2\sigma^2}} e^{j2\pi(\omega_x x + \omega_y y + \psi)} \]
                                    <div class="frame-highlight">
                                        <p>In the frequency domain, this results in <span class="bold">shifting the mean of the gaussian curve</span> from 0 to the frequency \( \omega_x \) and \( \omega_y \).
                                            This shifting comes from the <span class="bold">convolution of in the frequency domain</span> between the gaussian and a shifted impulse.</p>
                                    </div>
                                    It can be easier to consider it as a couple of real functions, dephased of \( \frac {\pi }{2} \), the first one being the real part and the second one the imaginary part.
                                    \[ G_1(x,y) = cos(\omega_x x + \omega_y b) e^{-\frac{x^2+\gamma^2 y^2}{2\sigma^2}}\]
                                    \[ G_2(x,y) = sin(\omega_x x + \omega_y b) e^{-\frac{x^2+\gamma^2 y^2}{2\sigma^2}}\]
                                    where \( \sigma \) is the standard deviation of the Gaussian function and \(u\) and \(v\) are the frequencies along the \(x\) and \(y\) axis. By changing the value of sigma, we change the bandwidth of the filter.
                                    The more sigma is small, the less the filter is selective. The more sigma is large, the more the filter is selective. Indeed, a compression in the frequency domain is an expansion in the spatial domain.
                                </p>
                            </div>    
                            
                            <button id="textures-illustrations"> Show illustrations</button>

                            <div> <h4>Statistical approach</h4>
                                <p>The <span class="bold">statistical</span> approach consists more in considering the occurences of patterns. For example, to spot repetitive interactions between 2 pixels separated by a distance \( d \),
                                    we can compute the <span class="bold">co-occurrence matrix</span> of the image.
                                    \[
                                        \Gamma(d,\theta) = \Gamma(dx,dy) = \frac{1}{N}
                                        \left(
                                        \begin{matrix}
                                            ... & ... & ...\\
                                            ... & P(X(i,j),X(i+dx,j+dy)) & ...\\
                                            ... & ... & ... \\
                                        \end{matrix}
                                        \right).   
                                    \]
                                    \(N\) is the number of pixels in the image, \(i(x,y)\) is the intensity of the 1st pixel and \(j(x,y)\) of the 2nd one. This formula makes things look harder than they really are.
                                    This matrix simply stores the number of occurences of each pair of intensity values \( i <-> j \). This pair is defined by the distance \(d\) and the angle \(\alpha\) between the two pixels.
                                    Hence, a co-occurrence matrix with a <span class="bold">strong diagonal</span> means that the image is <span class="bold">homogeneous</span> because the diagonal is where the intensity values \(i\) and \(j\) are the same.
                                    Usually, we compute multiple co-occurrence matrices with different values of \(d\) and \(\alpha\). We can extract several characteristics from them such as:
                                </p>
                                <div class="frame-highlight">
                                    <ul>
                                        <li>Entropy: \( H(d,\theta) \)</li>
                                        <li>Energy: \( E(d,\theta) \)</li>
                                        <li>Contrast: \( C(d,\theta) \)</li>
                                        <li>Homogeneity: \( Hom(d,\theta) \)</li>
                                        <li>Correlation: \( Corr(d,\theta) \)</li>
                                    </ul>
                                </div>
                                <p>Those are compliacted math formulas and are quite tough to grasp, so I shan't expand on them. Finally, we put them in a <span class="bold">Haralick vector</span> to represent the image.
                                    This vector is a vector of those characteristics and can be used to classify the image.
                                </p>
                                <p>Of course, the statistical approach is not restricted to this co-occurrence matrix. This is simply an example. Throughout this page, I will refer to other methods that are based on this approach.</p>
                                <button id="textures-illustrations"> Show illustrations</button>
                            </div>
                            <div> <h4>Texture generation</h4>
                                <p>The <span class="mark">synthesis of textures</span> is also a common practice in image processing. It consists of <span class="bold">generating a texture from a given model</span>. The model can be a texture or a set of textures.
                                    We start with a texture A and we generate a whole image different from A but that looks the same. Neither is it as simple as a copy-paste, nor a completely random operation. There exist several methods which are not fit for the same type of textures.
                                </p>
                                <div class="frame-highlight">
                                    <ul>
                                        <li><span class="bold">Image Quilting:</span> we slice the image in rectangles and at each border and we compute the overlapping error and merge borders where this error is the least significant.</li>
                                        <li><span class="bold">Chaos Mosaic:</span> we randomly copy-paste the input texture to form an image and we apply a low-pass filter on the image.</li>
                                        <li><span class="bold">Resampling:</span> we form each pixel by one, by taking into account its surrounding patterns.</li>
                                    </ul>
                                </div>
                            </div>
                        </div>
                        <hr>
                        <div class="subject-subdiv"> <h3>3. Image preprocessing</h3>
                            <p>Image preprocessing is fundamental in the field of image processing. It can save heavy computations by improving the quality of an image before processing it. </p>
                            <div> <h4>Histogram</h4>
                                <p>To describe an image, we can use a <span class="bold">histogram</span> that shows the occurences of each intensity value (it is a statistical approach). A histogram is a good indicator of the <span class="bold">dynamic</span>
                                    of an image. An example of a histogram done with Matlab is shown below. The illustration below shows an <span class="bold">anamorphosis</span> of the histogram. We started with a poorly contrasted image, applied a <span class="bold">normalization</span>
                                    to it. This process aims to maximize the range of intensities in order to make objects more distinguishable. The formula is \( I_s = \alpha I_e + \beta \), where \(I_s\) is the output image, \(I_e\) the source image.
                                </p>
                                <img style="width: 70%; margin: 0.5rem auto;" src="images/ai/histogram_example.PNG" alt="histogram">
                                <div class="frame-highlight">
                                    <p>What we mean by <span class="bold">dynamic</span> is the range of intensity values that the image contains. The less the dynamic, the harder it is to distinguish objects on the image.
                                        In this case, we say that the image has a <span class="bold">restrained dynamic</span> (left image).
                                        The word dynamic refers also to the <span class="bold">contrast</span> or <span class="bold">depth</span> of the image.
                                        However, the <span class="bold">resolution</span> refers to the number of pixels in the image.
                                    </p>
                                </div>
                                <p>In the example above, we applied a linear transform to go from \( I_e \) to \( I_s \). Nonetheless, we could choose to apply a <span class="bold">non-linear transform</span> to emphasize on a particular range of intensities.
                                    In the screenshot below, the brightest pixels have been more scaled than the darkest ones. This results in a histogram that is more spread on the right side.
                                </p>
                                <img style="width: 70%; margin: 0.5rem auto;" src="images/ai/histogram_example_nonlinear.PNG" alt="histogram">
                                <p>With the histogram, we can also spot where details of an image lie. <span class="bold">Details are located to the lowest occurences</span>. In the image above, details are mainly clustered from the 25th to 100th intensity level.
                                    To make these details more visible, we can apply a <span class="bold">histogram equalization</span>, which evenly spreads the histogram over the whole range of intensities.
                                </p>
                                <div class="frame-highlight">
                                    <p>This technique also amplifies the noise because noise is detail.</p>
                                </div>
                            </div>

                            <div id="object-segmentation"> <h4>Object segmentation</h4>
                                <p>We can use this histogram to distinguish objects from the background. Indeed, by choosing a background that is different from the object's overall intensity,
                                    we shall see 2 bumps on the histogram. This is called a <span class="bold">bi-modal histogram</span>. From this histogram, we can determine a <span class="bold">threshold</span>
                                    that will separate the range of intensities of the object from the background. Then, by applying a <span class="bold">binarization (also called thresholding)</span>, a pixel below the threshold,
                                    is set to 0 and a pixel above the threshold is set to 1. It may also happen that bumps are not clearly set apart, in that case we can use a <span class="bold">hysteresis thresholding</span>.
                                </p>
                                <div class="illustration-horiz">
                                    <img style="width: 30%; margin: 0.5rem auto;"" src="images/ai/sic.PNG" alt="sic">
                                    <img style="width: 30%; margin: 0.5rem auto;"" src="images/ai/sic_thresholding.PNG" alt="thresholding">
                                </div>
                                <p>However, this may result in adding an <span class="bold">impulse noise</span> to the image. This can be fixed by filtering the image with a <a href="#non-linear-filter">non-linear filter</a>.
                                    There exist different types of segmentation methods, I will expand on them when I will find the time.
                                </p>
                                <div class="frame-highlight">
                                    <ul>
                                        <li><span class="bold">Histogram methods:</span> Otsu, local thresholding and multpile thresholding, etc.</li>
                                        <li><span class="bold">Region transform methods:</span> Division-Fusion, region growth, etc.</li>
                                        <li><span class="bold">Optimization methods</span></li>
                                    </ul>
                                </div>
                            </div>

                            <div> <h4>Connectedness</h4>
                                <p>In an image, to move from one pixel to another one, we can use the <span class="bold">4-connectedness</span> or the <span class="bold">8-connectedness</span>. 
                                </p>
                            </div>

                            <div> <h4>Filtering</h4>
                                <div> <h5>Noise</h5>
                                    <p>In image processing, we try as much as possible to get rid of the noise before the actual image modification. This avoids expensive computations.
                                        There exist 2 types of noise in image processing: <span class="bold">additive</span> and <span class="bold">multiplicative</span>.
                                        In my case, I will only focus on the additive noise as it is the most common one. To modelize the noise, we use probabilities. Therefore, there are different types of noises:
                                    </p>
                                    <div class="frame-highlight">
                                        <ul>
                                            <li> <span class="bold">Impulse noise</span> (or salt-and-pepper).</li>
                                            <li> <span class="bold">Gaussian noise:</span> noise is centered on 0.</li>
                                            <li> <span class="bold">Uniform noise</span></li>
                                            <li> and many more ...</li> 
                                        </ul>                                     
                                    </div>
                                    <p>Depending on which probability law we assume the noise follows, we either use <span class="bold">linear filtering</span> or <span class="bold">non-linear-filtering</span>.
                                    </p>
                                </div>
                                <div> <h5>Linear Filtering</h5>
                                    <p>In 2D, we also have the concept of <span class="bold">convolution</span> that is used to filter an image. The convolution is defined as follows:
                                        \[ I(u,v) = \sum^{u}_{-\infty}\sum^{v}_{-\infty} I(x,y) h(u-x,v-y) dxdy \]
                                        \(I(u,v)\) is the output image, \(I(x,y)\) is the input image, \(h(u,v)\) is the filter and \(u\) and \(v\) are the spatial coordonates.
                                    </p>
                                    <div class="frame-highlight">
                                        <p>In signal processing, the filter's impulse response must be <span class="bold">causal</span>, it is a physical limit. However, <span class="bold">we do not have this constraint</span> for image processing, as
                                            we treat the image in <span class="bold">deferred time (spatial filtering)</span>, thus we can use non-causal filters. Our filter will be centered on the pixel we want to filter using surrounding pixels. 
                                        </p>
                                    </div>
                                    <p>Our filter requires accessing all surrounding pixels, hence pixels at borders are quite unconvenient.
                                        In these cases, we need to extend our image to be able to operate the filter. There exist 3 main techniques:
                                    </p>
                                    <div class="frame-highlight">
                                        <ul>
                                            <li><span class="bold">Zero-Padding:</span> can introduce discontinuities to the image</li>
                                            <li><span class="bold">Image mirroring</span></li>
                                            <li><span class="bold">Image periodization</span></li>
                                        </ul>
                                    </div>
                                    <p>Finally, linear filters are fit for filtering the gaussian noise. The pictures below show the impact of an average filter of size 3x3, 5x5, 7x7.
                                    </p>
                                </div>
                                <div id="non-linear-filter"> <h5>Non-linear Filtering</h5>
                                    <p>To filter <span class="bold">impulse noise</span>, we <span class="bold">cannot use linear filters</span> because instead of diminishing the noise they spread it over the surrounding pixels.
                                        On the other hand, non-linear filters, such as the <span class="bold">median filter</span>, allow to tackle this issue by considering a statistical approach rather than a spectral one.
                                        In the case of the median filter, all pixels contained within the kernel are <span class="bold">ranged by intensity</span>. As a result,
                                        the noise is likely to be the among the lowest or highest values and will be discarded. The median value is chosen as the pixel's output value. 
                                    </p>
                                </div>
                            </div>

                            <div> <h4>Math morphology</h4>
                                <p>In a context where we need to detect objects on an image, we already saw that we needed to perform a <a href="#object-segmentation">segmentation</a> using <span class="bold">histograms and thresholding</span> (or binarization).
                                    However, it turns out that objects may not be properly segmented. Therefore, we need a method which can correct object's shapes such that they are segmented as we wish.
                                    This is where <span class="bold">math morphology</span> comes in. It has 2 parameters to set: <span class="bold">Application point</span> and <span class="bold">Element's shape</span>.
                                </p>
                                <div class="frame-highlight">
                                    <ul>
                                        <li><span class="bold">Erosion:</span> to erase objects from the image (small imperfections, excrescence ...)</li>
                                        <li><span class="bold">Dilatation:</span> to fill holes in a shape</li>
                                    </ul>
                                </div>
                                <p>Usually we apply an erosion followed by a dilatation to get rid of small imperfections and fill holes. This is called an <span class="bold">opening</span>.
                                    We can also apply a dilatation followed by an erosion to fill holes and get rid of small imperfections. This is called a <span class="bold">closing</span>.
                                    The order of these operations matters !!!
                                </p>
                                <div> <h5>Gray levels</h5>
                                    <p>When considering the image with multiple levels of gray, </p>
                                </div>
                            </div>

                            <div> <h4>Blur</h4>
                                <p>Usually blur is the <span class="bold">outcome of a low-pass filtering</span>. A low-pass filter widens the <span class="bold">transition area</span> between pixels which leads to reducing the contrast (sharp discontinuities) of objects shapes.
                                    To counter this effect, we can substract the original image to the <span class="bold">Laplacian of the image</span>:
                                    \[ I(x,y) = I(x,y) - \lambda \Delta I(x,y) \]
                                    To have a better understanding of what the Laplacian is, click <a href="math&IT.html">here</a>. In short, this is the second derivative of a 2D function.
                                    Performing this operation on the image's pixels will enhance the contrast of the image.
                                </p>
                            </div>
                        </div>
                        <hr>
                        <div> <h3>Hands-on image processing</h3>
                            <div> <h4>Matlab</h4>
                                <p>On Matlab, we can use the function <span class="bold">graycomatrix</span> to compute the co-occurrence matrix and the function <span class="bold">graycoprops</span> to compute the its <span class="bold">Haralick vector</span>.
                                </p>
                            </div>
                            <div> <h4>OpenCV</h4>
                                <p>I work with Google Colab. I will upload soon a notebook with some examples.</p>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="subject-container"> <div class="label"> <h2>Digital Embedded Systems</h2> </div>
                    <div class="keywords">OS architectures, performances, parallelism paradigm (semaphores), process, FreeRTOS</div>
                    <p>You can consult some <a href="currentprojects.html" target="_parent">projects</a> done as part of this course.</p>
                    <div class="content">
                        <p>Our purpose in this course is to understand what are the impacts of the sampling on an analog signal.</p>
                        <p style="font-style: italic;">In this course, we had a <a href="sen_proj.html">project</a> in which we had to ... .</p>
                        <div class="subject-subdiv"> <h3>1. Architectures</h3>
                            <p>Parallelism</p>
                        </div>
                    </div>
                </div>

                <div class="subject-container"> <div class="label"> <h2>Network & Communication Systems</h2> </div>
                    <div class="keywords">Networking concepts, UDP / TCP, HTTPS , Sockets, CAN / UART / I²C / SPI</div>
                    <div class="content">
                        <p>This course is organised around lab sessions where we simulated virtual networks (use of VMs). It involved a practical project as well.</p>
                        <p>You can find code that we encountered during these network classes by clicking <a href="network.html" style="color: black;">here</a>.</p>
                        <hr>
                        <div class="subject-subdiv"> <h3>1. Fundamentals: Addressing / Routing / Firewall</h3>
                            <p>In these lab sessions, we basically covered :</p>
                            <div class="frame-highlight">
                                <ol>
                                    <li> <span class="bold">The difference between hubs and switchs;</span> </li>
                                    <li> <span class="bold">How to configure a network interface;</span> </li>
                                    <li> <span class="bold">Basic protocols such as ICMP and ARP (MAC & IP addresses);</span> </li>
                                    <li> <span class="bold">OSI and TCP/IP models, encapsulation of data, subnet-mask;</span> </li>
                                    <li> <span class="bold">Reachability, hierarchial network structure;</span> </li>
                                    <li> <span class="bold">IP forwarding , routing table;</span> </li>
                                    <li> <span class="bold">TTL (Time To Live)</span> </li>
                                    <li> <span class="bold">SNAT, DNAT;</span> </li>
                                    <li> <span class="bold">Firewall (filtering network traffic).</span> </li>
                                </ol>
                            </div>
                        </div>
                        <hr>
                        <div class="subject-subdiv"> <h3>2. Process & Sockets</h3>
                            <p>In these lab sessions, we basically covered :</p>
                            <div class="frame-highlight">
                                <ol>
                                    <li> <span class="bold">Multi-threading, pipe and syscalls;</span> </li>
                                    <li> <span class="bold">UDP sockets;</span> </li>
                                    <li> <span class="bold">TCP sockets;</span> </li>
                                    <li> <span class="bold">Sockets performances.</span> </li>
                                </ol>
                            </div>
                            <p>In Linux everything is a file. For example, writing into a socket is like writing in a file.
                                The kernel creates a pipe that can be written into or read from via a file descriptor (fd).
                            </p>
                            <div class="linux-terminal">
                                <div>$ man write / read / open, close</div>
                                <div>$ man socket / bind / send</div>
                                <div>$ man accept / </div>
                            </div>
                        </div>
                        <hr>
                        <div class="subject-subdiv"> <h3>X. Important config commands</h3>
                            <div class="linux-terminal">
                                <div>$ ip link set dev <span style="font-style: italic;">eth0</span> up   /* Set up the eth0 network interface */</div>
                                <div>$ ip addr [add/del] <span style="font-style: italic;">[IP/mask]</span> dev eth0   /* Add a new IP to eth0 */</div>
                                <div>$ ip route add default via <span style="font-style: italic;">IP</span> /* Add a default route to a host */</div>
                                <div>$ echo 1 >/proc/sys/net/ipv4/ip_forward   /* Enables the OS to perform IP forward */</div>
                                <div>$ iptables -t nat -A [PREROUTING/POSTROUTING] -s [IP/mask] -p [] --dport [] [-to--source/-to--destination]   /* Enables the OS to SNAT and DNAT */</div>
                                <div>$ ip filter -A [INPUT/OUTPUT/FORWARD] DROP   /* Enables the OS to act like a firewall (block all communications) */</div>
                                <div>$ tcpdump -eni <span style="font-style: italic;">eth0</span>   /* Listen to traffic on eth0 */</div>
                            </div>
                        </div>
                    </div>
                </div>

                <div class="subject-container"> <div class="label"> <h2>Interface Power Systems</h2> </div>
                    <div class="keywords">Closed-loop / feedback systems, sensors, motors, power electronics</div>
                    <div class="content">
                        <div> <h3>1. Resistive and reactive sensors</h3>
                            <p><a href="ips_proj.html">project</a></p>
                        </div>
                    </div>
                </div>

                <div class="subject-container"> <div class="label"> <h2>Company administration & management</h2> </div>
                    <p style="font-style: italic;">The following section will be in french because I do not know precisely the vocabulary related to finance and management.</p>
                    <div class="keywords">Mots clés : Comptabilité française, Finance, Gestion, Management</div>
                    <div class="content">
                        <p>Ce cours couvre les fondamentaux de la gestion comptable d'une entreprise.</p>
                        <hr>
                        <div class="subject-subdiv"> <h3>1. Bilan, Compte de Résultat et Flux de Trésorerie</h3>
                            Le schéma ci-dessous (en cours d'élaboration) résume les principaux éléments de ses documents.
                            <img src="images/MAE_Chap1.svg" alt="mae">
                        </div>
                        <hr>
                        <div class="subject-subdiv"> <h3>2. TVA</h3>
                            <p>La TVA est neutre pour les entreprises. Elles jouent le rôle de percepteur auprès de l'état. Lorsqu'une entreprise vend ses services ou produits, elle doit reverser 20% de
                                ses produits à l'état (TVA due = dettes auprès de l'état), lorsqu'elle achète des services ou marchandises auprès d'autres entreprises, elle les paie T.T.C. mais 20% de ses charges sont
                                remboursées par l'état (TVA déductible = créances auprès de l'état).
                            </p>
                        </div>
                        <hr>
                        <div class="subject-subdiv"> <h3>3. Sources d'investissements</h3>
                            <p>R&D</p>
                            <ul>
                                <li>Source d'investissements internes: Capital social, apport au compte courant des associés, autofinancement, subventions</li>
                                <li>Source d'investissements externes: Emprunt, LOA (Location avec Option d'Achat)</li>
                            </ul>
                        </div>
                        <hr>
                        <div class="subject-subdiv"> <h3>4. Dotations</h3>
                            <p>...</p>
                        </div>
                        <div class="subject-subdiv"> <h3>5. Calcul des coûts complets d'un produit par la méthode des centres d'analyses</h3>
                            <p>Afin de déterminer, les coûts complets d'un produit, nous utilisons la méthode des centres d'analyses. Elle consiste en 8 étapes:</p>
                            <div class="frame-highlight">
                                <span class="bold">Répartition des charges indirectes</span>
                                <ol>
                                    <li>Répartition primaire: charges indirectes réparties sur les centres principaux et de structures.</li>
                                    <li>Répartition secondaire: ajout des charges des centres auxiliaires réparties sur les centres principaux .</li>
                                    <li>Coût d'une Unité d'oeuvre (UO): répartition secondaire finale * quantité d'UO.</li>
                                </ol>
                            </div>
                            <!-- <p></p> -->
                            <div class="frame-highlight">
                                <span class="bold">Coût d'achat</span>
                                <p>Cela couvre l'ensemble des processus impliqués dans l'acheminement de biens nécessaires à la fabrication d'un produit: 
                                Charges directes + Charges indirectes liées à l'achat (approvisionnement, réception livraisons ...).
                                </p>
                                <ul>
                                    <li>Prix d'achat nets des MP.</li>
                                    <li>Charges de main d'oeuvre directe (pas la main d'oeuvre employée pour la fabrication du produit !).</li>
                                    <li>Accessoires d'achats: transport.</li>
                                </ul>
                            </div>
                            <p></p>
                            <div class="frame-highlight">
                                <span class="bold">Etude des stocks de matières premières (MP)</span>
                                <ol>
                                    <li>Stock initial / Stock consommé: Quantité, coût unitaire, valeur.</li>
                                    <li>Achat début mois / Stock final: Quantité, coût unitaire, valeur.</li>
                                </ol>
                            </div>
                            <p></p>
                            <div class="frame-highlight">
                                <span class="bold">Coût de production</span>
                                <ol>
                                    <li>Stock initial / Stock consommé: Quantité, coût unitaire, valeur.</li>
                                    <li>Production du mois / Stock final: Quantité, coût unitaire, valeur.</li>
                                </ol>
                            </div>
                            <p></p>
                            <div class="frame-highlight">
                                <span class="bold">Etude des stocks de prdouits finis (PF)</span>
                                <ol>
                                    <li>Stock initial / Stock vendus: Quantité, coût unitaire, valeur.</li>
                                    <li>Production du mois / Stock final: Quantité, coût unitaire, valeur.</li>
                                </ol>
                            </div>
                            <p></p>
                            <div class="frame-highlight">
                                <span class="bold">Coût de production</span>
                                <ol>
                                    <li>Stock initial / Stock consommé: Quantité, coût unitaire, valeur.</li>
                                    <li>Production du mois / Stock final: Quantité, coût unitaire, valeur.</li>
                                </ol>
                            </div>
                            <p></p>
                            <div class="frame-highlight">
                                <span class="bold">Calcul du coût de revient</span>
                                <p>Il s'agit du montant nécessaire à dépenser pour l'entreprise afin de fabriquer un produit:
                                    Coût des PF vendus + Coût hors-production
                                </p>
                            </div>
                        </div>
                    </div>
                </div>

            </section> <!-- accordion -->
        
        </section> <!-- main-container -->

        <div id="footer"></div>

    </body>

</html>