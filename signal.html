<!DOCTYPE html>

<html lang ="en">

    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- make sure that the content fit the device on which we open -->
        <title> Math </title>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Audiowide|Sofia|Trirong|Arial|Open+Sans">
        <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
        <script src="js/script.js"></script>
        <link rel="stylesheet" href="generic-patterns/css/main.css">
        <link rel="stylesheet" href="generic-patterns/css/horizontalmenu.css">
        <link rel="stylesheet" href="generic-patterns/css/footer.css">
        <link rel="stylesheet" href="css/topics.css">
    </head>

    <!-- Within de web page -->
    <body>
        <div id="horizontalmenu"></div>
        
        <section class="main-container">

            <h1>Further discussions: Signal processing</h1>
            <div class="page-subtitle">This page expands on diverse and self-explored topics related to signal processing.
                I endeavor to convey back what I learn using my own words to strengthen my knowledge. I try to clarify some questions that came to me while studying the subject.
                <a href="https://colab.research.google.com/drive/1urd-ix9vSj0F_J_-vPLFqPb8ttrotL8a?hl=fr#scrollTo=jm0wkaFrti8H&uniqifier=1">Here</a> a notebook where I experiment some of the concepts discussed below.
            </div>
            
            <div class="frame-highlight">
                <h4>Overview</h4>
                <p>Here is the overview of the topics that I covered:</p>
                <ol>
                    <a href="#hilbert"><li>FFT, Hilbert transform and its concrete applications;</li></a>
                    <a href="#laplace"><li>Laplace transform and Z-transform</li></a>
                    <a href="#wavelet"><li>Wavelet analysis</li></a>
                    <li>Some modulation techniques such as QAM16, OFDM and QPSK;</li>
                    <li>Signal encoding and encryption;</li>
                    <li>Some communication protocols on the physical layer.</li>
                </ol>
            </div>

            <div id="hilbert"> <h2>Hilbert analysis</h2>
                <div> <h3>Discrete Fourier Transform (DFT)</h3>
                    <div> <h4>Questions and clarifications</h4>
                        <div> <h5>Why is this used for ?</h5>
                            <p>This transform allows us to better identify the <span class="bold">contribution of frequencies</span> in a signal, which most of time are <span class="bold">not noticeable</span> when looking at the signal in its <span class="bold">time representation</span>.
                                However, to be able to manupilate the spectrum density with a computer, the signal (represented in both domains) has to be <span class="bold">finite and discrete</span> (i.e., limited number of points/samples \(N\)).
                                The DFT essentially performs both signal <span class="bold">sampling</span> and spectrum <span class="bold">quantization</span>.
                                In fact, the DFT is simply a <span class="bold">discrete version</span> of the Fourier transform. As a result, integrals are replaced by <span class="bold">sums</span>.
                                \[ X[k] = \sum_{n=0}^{N-1} x[n] e^{-i2\pi kn/N} \]
                                \(k\) is the <span class="bold">frequency index</span> of the discrete spectrum and determines how fast (frequency) we travel around the complex unit circle (1 round = 1 cycle of the signal's time length), and \(n\) is the <span class="bold">time index</span> of the signal sampled at each \(T_e\).
                            </p>
                            <div class="frame-highlight">
                                <p>This can also be viewed as a <span class="bold">dot product</span> between the signal and the complex exponential domain. The result evaluates the <span class="bold">correlation</span> between those.</p>
                            </div>
                            <p>However, \(k\) and \(n\) are not directly the <span class="bold">physical frequency</span> and <span class="bold">time</span> of the signal, which can be retrieved using the following formulas:
                                \[ f = \frac{k}{N T_e} \]
                                \[ t = \frac{n}{T_e} \]
                                where \(f\) is the <span class="bold">physical frequency</span>, \(t\) is the <span class="bold">physical time</span> and \(NT_e\) is the <span class="bold">length of the signal</span>.
                            </p>
                            <p>As a result, we increment the \(k\) index to know the <span class="bold">contribution</span> of each frequency in the signal.
                                With the illustration below, that may come clearer. It illustrates how the length of the signal \(NT_e\) is related to the index \(k\).
                            </p>
                            <img src="images/signal/dft_k_meaning.PNG" alt="">
                            <p>\(k=0 \rightarrow \) 0 cycle around the circle | \(k=1 \rightarrow \) 1 cycle around the circle | \(k=2 \rightarrow \) 2 cycle around the circle</p>
                        </div>
                        <div> <h5>Why are there negative frequencies at all ?</h5>
                            <p>Negative frequencies account for <span class="bold">information redundancy</span>. This redundancy comes from the fact that in the complex domain there is a <span class="bold">complex conjugate symmetry</span>.
                                This results in the following property: \( arg(e^{i\omega}) = -arg(e^{i(2\pi-\omega)}) = -arg(e^{-i\omega}) \).
                                Also, \(e^{i\theta}\) is a <span class="bold">periodic</span> function: \( e^{i\theta} = e^{i(2\pi+\theta)} \). This is due to the Euler's formula: \(e^{i\theta} = cos(\theta) + isin(\theta)\).
                            </p>
                            <p>Therefore, performing an <span class="bold">anti-clockwise</span> (positive frequencies first) or <span class="bold">clockwise</span> (negative frequencies first) rotation is equivalent.
                                This has no impact on the <span class="bold">magnitude</span> of each frequency, but only their <span class="bold">phase</span>.
                                So all angles (i.e., each frequency's contribution) taken after \(\pi\) (i.e., \(k > \frac{N}{2}\)) are redundant (with a change in the sign) because we basically measure the same frequencies before and after \(\pi\).The direction of the rotation is the only difference.
                            </p>
                            <div class="frame-highlight">
                                <p>Note that instead of taking negative frequencies \(-i\omega\), we could take \(i(\omega + \pi) \). The result would be a <span class="bold">double-sided</span> graph with only positive frequencies.
                                    In Matlab, we can use <span class="bold">fftshift</span> to have the graph centered on 0 and consequently having the negative frequencies appear (right side graph).</p>
                                <div class="illustration-horiz-4">
                                    <img src="images/signal/double-sided-fft.webp" alt="">
                                    <img src="images/signal/double-sided-fftshift.webp" alt="">
                                </div>
                                <p>This redundancy means that we could only deal with the <span class="bold">first half</span> of the graph. By doing so we obtain a so-called <span class="bold">one-sided</span> spectrum where only <span class="bold">positive frequencies</span> remain.
                                    This graph contains all necessary information to reconstruct the original signal.
                                </p>
                                <img style="width: 20%; margin: 0 auto;" src="images/signal/one-sided-fft.webp" alt="">
                            </div>
                            <p>At some point when \(k\) is greater than \(N/2 \equiv \pi\), the negative frequencies become simply the <span class="bold">conjugate</span> of the positive frequencies. That means, we could re-write the DFT as:
                                \[ X[k] = \sum_{n=0}^{N-1} x[n] e^{i2\pi kn/N} \]
                                The \(-\) sign in the exponential term was removed which causes to travel around the circle in the <span class="bold">positive direction</span>.
                            </p>
                            <div class="illustration-horiz-2">
                                <p>The image on the right introduces a visual interpretation of this transform. We clearly see that \( X[k] \) is a complex vector composed of \( C_{k_n} \) and \( S_{k_n} \) which respectively account for <span class="bold">frequency correlation</span> of cosinus and sinus for different frequencies.
                                    From this complex signal, we can calculate the <span class="bold">frequency contribution</span> \(A_{k_n}\) and the <span class="bold">phase</span> \(\theta_{k_n}\) at each frequency index.
                                    We can also notice that if we keep only the green part of \(X[k]\), we get back to the real signal \(x[n]\) but we lose information about the instantenous amplitude and phase of the signal.
                                    This complex nature of the signal will be used for the extraction of a so-called <span class="bold">analytic signal</span> that uses the <a href="#hilbert">Hilbert transform</a> section.
                                </p>
                                <img src="images/signal/X[k]_complex_illustration.drawio.png" alt="">
                            </div>
                        </div>
                        <div> <h5> Why do we sometimes only consider the absolute value of the FFT ?</h5>
                            <p>The absolute value informs us about the <span class="bold">contribution</span> (weight) of the specific frequency \(f=\frac{k}{NTe}\) to the signal <span class="bold">regardless of the phase correlation</span>.
                                Therefore, as far as the magnitude is concerned, it does not matter in which direction we travel the circle around.
                            </p>
                        </div>
                        <div> <h5>What does the phase of the FFT actually tell us ?</h5>
                            <p>The phase of the FFT is: \( \phi(t) = arctan(\frac{S_k sin(2\pi\frac{k}{N}n)}{C_k cos(2\pi\frac{k}{N}n)}) \), where \(S_k\) and \(C_k\) are <span class="bold">correlation coefficients</span> computed with the DFT for a given frequency index \(k\).</p>
                            <ul>
                                <li>If the phase becomes positive (> 0°), it means that the signal is <span class="bold">more correlated</span> with the imaginary part (sinus) of the complex exponential.</li>
                                <li>If the phase becomes negative (< 0°), it means that the signal is also <span class="bold">more correlated</span> with the imaginary part.</li>
                                <li>If the phase is around 0°, it means that the signal is also <span class="bold">more correlated</span> with the real part part (cosinus).</li>
                            </ul>
                        </div>
                        <div> <h5>To what extent does the <span class="bold">Nyquist frequency</span> theorem explain the redundancy of information with the FFT (negative frequencies) ?</h5>
                            <p>The value \(k\) accounts for how <span class="bold">many cycles</span> (periods) of the length of the signal we travel. Actually, the <span class="bold">maximum frequency</span> that should be considered is \( f=\frac{k}{NT_e} \leq \frac{f_e}{2} \implies k_{max}=\frac{N}{2} \).
                                Beyond this value, the frequency spectrum <span class="bold">gets folded back on itself</span> and information is <span class="bold">duplicated</span>. This is where negative frequencies show up.
                            </p>
                        </div>
                        <div> <h5>Example</h5>
                            <div class="frame-highlight">
                                <p>Let's take an example to better understand this. Let's consider we sample a signal over 1 second with 10 points (i.e., \(N=10\)). This implies that \(f_e=10\)Hz so \(f_{max}=5\)Hz.
                                    Therefore, the <span class="bold">frequency resolution</span> is \(\delta \omega=\frac{2\pi}{NT_e} \implies \delta f=\frac{1}{NT_e} = 1\)Hz.
                                    <ol>
                                        <li><p>Now we want to know how much the \(k=1\) frequency contributes to the signal. The frequency tested here is \(f_{k=1}=\frac{1}{NT_e}=1\)Hz which results in traveling the unit circle with this angle pace \(\widehat {x}[n]=2\pi\frac{n}{10}\), \(0 \leq n \leq N-1=9\).</p></li>
                                        <li><p>Also let's consider the case where \(k=9\). The frequency tested here is \(f_{k=9}=\frac{9}{NT_e}=9\)Hz, we have got: \(\widehat {x}[n]=2\pi\frac{9n}{10}=-2\pi\frac{n}{10}\), \(0 \leq n \leq N-1=9\).</p></li>
                                    </ol>
                                    <p>As we can see, though we increase the frequency, the <span class="bold">speed</span> at which we travel the circle <span class="bold">does not increase</span>, only the <span class="bold">sign of the direction</span> changes <span class="bold">(negative sign)</span>.
                                        This effect shows clearly the effect of the <span class="bold">Nyquist-Shannon criterion</span>, beyond \(k=\frac{N}{2}\) (so \(k=5\) in that case), the frequency gets <span class="bold">folded back on itself</span> causing negative frequency values to appear.
                                        As a result, these frequencies do not bring <span class="bold">any new information</span> to the signal.
                                        We conclude that the \(\pi\) <span class="bold">periodicity</span> of the complex exponential domain is the reason why we have negative frequencies. In fact, the negative frequencies are the conjugate of the positive frequencies.
                                    </p>
                                </p>
                            </div>
                        </div>
                    </div>
                    <div> <h4>The FFT</h4>
                        <div> <h5>A different approach</h5>
                            <p>The DFT formula can be re-written as a matrix operation (vector rotation) between the <span class="bold">sampled signal</span> and the <span class="bold">complex exponential domain</span>.
                                \[ X[k] = \begin{bmatrix} X_0 \\ X_1 \\ \vdots \\ X_{N-1} \end{bmatrix} =
                                \begin{bmatrix}
                                    1 & 1 & 1 & \cdots & 1 \\
                                    1 & e^{-i2\pi k/N} & e^{-i2\pi (2k)/N} & \cdots & e^{-i2\pi (N-1)k/N} \\
                                    1 & e^{-i2\pi k/N} & e^{-i2\pi (2k)/N} & \cdots & e^{-i2\pi (N-1)k/N} \\
                                    \vdots & \vdots & \vdots & \ddots & \vdots \\
                                    1 & e^{-i2\pi k/N} & e^{-i2\pi (2k)/N} & \cdots & e^{-i2\pi (N-1)k/N} \\
                                \end{bmatrix}
                                \times
                                \begin{bmatrix} x_0 \\ x_1 \\ \vdots \\ x_{N-1} \end{bmatrix}
                                \]
                                As mentioned earlier, we obtain a <span class="bold">complex vector</span> \(X[k]\) (each component is a complex exponential number) of length \(N\), which is the same length as the signal \(x[n]\).
                                The matrix has <span class="bold">symmetries</span> (due to the periodicity of the complex exponentials) that can be leveraged to reduce the number of complex multiplications, which is the goal of the <span class="bold">FFT algorithm</span>.
                            </p>
                            <div class="frame-highlight">
                                <p>Note that each component of the \(X[k]\) can also be seen as a polynom \( X[k] = \sum_{n=0}^{N-1} \lambda_n \omega^n_k \), with \( \lambda_n = x_n \) and \( \omega_k = e^{-i2\pi k/N} \).
                                    This representation will be used further in an algorithm.
                                </p>
                            </div>
                        </div>
                        <div> <h5>My understanding</h5>
                            <p>As considered earlier on this page, traveling the circle with \(2\pi\frac{k+\frac{N}{2}}{N}n = 2\pi\frac{k}{N}n +\pi n \mod 2\pi = -2\pi\frac{k}{N}n \mod 2\pi \). As a result we conclude that for \(k > \frac{N}{2}\) indices the exponential number is the conjugate of the exponential number at \(k\).
                                The example below illustrates this periodicity for \(n=1\), we take all possible values of \(k < N-1\).
                                \[ \left\{
                                \begin{matrix}
                                    X[0] = x[0]e^{-i2\pi 0n/N} \\
                                    X[1] = x[0]e^{-i2\pi n/N} \\
                                    \vdots \\
                                    X[N-2] = x[0]e^{-i2\pi n\frac{N-2}{N}} = x[0]e^{i2\pi \frac{2n}{N}} = Re(X[2])-iIm(X[2]) \\
                                    X[N-1] = x[0]e^{-i2\pi n\frac{N-1}{N}} = x[0]e^{i2\pi \frac{n}{N}} = Re(X[1])-iIm(X[1]) \\
                                \end{matrix}
                                \right.
                                \]
                                We clearly notice that we cut <span class="bold">by half the number of complex computations</span>. It is also important to notice that this periodicity applies to the <span class="bold">time axis</span> \(n\) as well.
                                \[ X[k] = x[0]e^{-i2\pi 0k/N} + x[1]e^{-i2\pi k/N} + \cdots + x[N-2]e^{i2\pi \frac{2k}{N}} + x[N-1]e^{i2\pi \frac{k}{N}} \]
                                \[ \implies X[k] = x[0]e^{-i2\pi 0k/N} + x[1]e^{-i2\pi k/N} + \cdots + x[N-2]\frac{(Re(X[k]_{x[2]})-Im(X[k]_{x[2]}))}{x[2]} + x[N-1]\frac{)Re(X[k]_{x[1]})-Im(X[k]_{x[1]}))}{x[1]} \]
                                where \(X[k]_{x[n]} = x[n]e^{-i2\pi kn/N}\) is the complex exponential number at \(k\) for \(x[n]\). This value is assumed to be already computed.
                            </p>
                        </div>
                        <div> <h5>Application: Cooley-Tukey FFT algorithm</h5>
                            <p>This algorithm separates even and odd signal's indices</p>
                            <ol>
                                <li>Even/odd sepration</li>
                                <li>Circular periodicity</li>
                                <li>Recursive computations</li>
                            </ol>
                            <p>\[ \left\{
                                \begin{matrix}
                                X[k] = E[k] + e^{-i2\pi k/N}O[k] \\
                                X[k+\frac{N}{2}] = E[k] - e^{-i2\pi k/N}O[k] \\
                                \end{matrix}
                                \right.
                                \]

                            </p>
                        </div>
                    </div>
                </div>
                <div> <h3>From the DFT to the HT</h3>
                    <p>The <span class="bold">Hilbert transform</span> relies on the Fourier transform. Its main goal is to construct an <span class="bold">analytic signal</span> which provides relevant information about the real signal.</p>
                    <p></p>
                    <div> <h4>Procedure</h4>
                        <p>Here are the steps that are executed when we operate the Hilbert transform of a signal:</p>
                        <div class="frame-highlight">
                            <ol>
                                <li>Compute the original signal's <span class="bold">FFT</span>;</li>
                                <li>Shift by <span class="bold">-90°</span> all frequencies <span class="bold">above</span> 0 and by <span class="bold">90°</span> all frequencies <span class="bold">below</span> 0 (or above \(\pi\))</li>
                                <li>Compute the <span class="bold">IFFT</span> of the transformed signal.</li>
                            </ol>
                        </div>
                        <p>It is important to see that this procedure does not affect the amplitude spectrum. This means that the <span class="bold">frequency correlation itself does not change</span> (i.e., detected frequencies are the same as before).
                            This has the new signal become <span class="bold">orthogonal</span> to the original one. As a result the Hilbert transform computes a signal in the <span class="bold">same domain</span> (time domain) but with a <span class="bold">phase shift</span> of 90°. This is given by this formula:
                            \[ \mathcal{H}(x(\tau))(t) = \widehat x(t) = \frac{1}{\pi} \int_{-\infty}^{+\infty} \frac{x(\tau)}{t-\tau} d\tau = (x(\tau)*\frac{1}{\pi \tau})(t) \]
                            where \(x(t)\) is the original signal and \(\widehat {x}(t)\) is the <span class="bold">phase shift</span> of the new signal. This formula might seem daunting but we can switch to the <span class="bold">Fourier domain</span> to make it more understandable.
                            \[ \mathcal{F}(\frac{1}{\pi t}) = -i sgn(\nu) \implies \mathcal{F}(\widehat x(t)) =
                            \left\{
                            \begin{matrix} X(\nu)e^{-i2\pi},\ \nu > 0 \\ X(0) = 0 \\ X(\nu)e^{i2\pi},\ \nu < 0 \end{matrix}
                            \right.
                            \]
                            where \(X(\nu)\) is the original signal's Fourier transform. This formula shows clearly the <span class="bold">+/- 90° phase shift</span>.
                        </p>
                    </div>
                    <div> <h4>Analytic signal</h4>
                        <p>This transform aims at extracting this new analytic <span class="bold">(complex)</span> signal:
                            \[ x_a(t) = x(t) + j \mathcal{H}(x(t)) = x(t) + j \widehat {x}(t) = A(t) e^{j\theta(t)} \rightarrow
                            \left\{
                            \begin{matrix} A(t) = \sqrt{x(t)^2 + \widehat {x}(t)^2} \\ \theta(t) = arctan(\frac{\widehat {x}(t)}{x(t)}) \end{matrix}
                            \right.
                            \]
                            where \(x(t)\) is the original signal and is also called the <span class="bold">base-band</span> signal. \(\widehat {x}(t)\) is the <span class="bold">phase shift</span> of the original signal.
                        </p>
                        <p>This signal features an interesting property which is to <span class="bold">remove information redundancy</span>, thereby having only <span class="bold">positive frequencies</span> in its Fourier spectrum.</p>
                        <div class="frame-highlight">
                            <p>This signal can also be computed by following these steps:</p>
                            <ol>
                                <li>Compute the original signal's <span class="bold">FFT</span>;</li>
                                <li>Set all <span class="bold">negative</span> frequencies coefficients to 0;</li>
                                <li>Double all <span class="bold">positive</span> frequencies coefficients for <span class="bold">energy conservation</span>;</li>
                                <li>Compute the <span class="bold">IFFT</span> of the transformed signal.</li>
                            </ol>
                        </div>
                        <p>It is really important to grasp the purpose of this procedure and how we do end up with this <span class="bold">analytic signal</span> in the end. By setting all negative frequencies coefficients to 0 (2), we actually prevent 
                            that signal from <span class="bold">becoming real</span> again when computing the IFFT (4).
                            Indeed, in the Fourier domain, negative frequencies coefficients allow, when added with positive frequencies coefficients, to <span class="bold">cancel out the imaginary part</span> of the complex exponential, thereby obtaining a <span class="bold">real signal</span>.
                            What the IFFT essentially does is this:
                            \[ x[n] = \sum_{k=0}^{N-1} X[k] e^{i2\pi kn/N} = X[0] + \sum_{k=1}^{N/2} X[k] e^{i2\pi kn/N} + X[N-k] e^{-i2\pi kn/N},\ with\ X[k]=\overline{X[N-k]} \] 
                            To obtain the <span class="bold">analytic signal</span>, we actually do this:
                            \[ x_a[n] = \sum_{k=0}^{N/2} X[k] e^{i2\pi kn/N} = X[0] + 2\sum_{k=1}^{N/2} X[k] e^{i2\pi kn/N} = X[0] + 2\sum_{k=1}^{N/2} (C_k + i S_k) e^{i2\pi kn/N} \]
                            where \(C_k\) and \(S_k\) are respectively the cosinus and sinus <span class="bold">correlation coefficients</span> computed with the DFT for a given frequency index \(k\). The \(2\) accounts for <span class="bold">energy conservation</span>, it compensates for the cancellation of negative frequencies.
                            Eventually, we notice that the signal is <span class="bold">complex</span> because we stop at \(k=\frac{N}{2}\) andt to make the link with the parameter calculated in the section just above (\A(t)\) and \(\theta(t)\), we can re-write \(x_a[n]\) such as:
                            \[ x_a[n] = X[0] + \sum_{k=1}^{N/2} A_k e^{i \theta_k} e^{i2\pi kn/N} = X[0] + A[n] e^{i \theta[n]} \]
                            where \(A_k\) and \(\theta_k\) are respectively the <span class="bold">magnitude</span> and <span class="bold">phase</span> of the signal for each \(k\). In the eend, this signal carries the same information as \(C_k\) and \(S_k\) but in a different form.
                            With this approach, we have now a complex signal from which we can extract several features of the original signal such as the instantaneous <span class="bold">amplitude</span> \(A[n]\) and <span class="bold">phase</span> \(\theta[n]\).
                        </p>
                    </div>
                    <div> <h4>Application</h4>
                        <p>Let's take a simple example to understand that better.</p>
                        <div class="frame-highlight">
                            <p>Imagine we want to analyse the following real signal: \( x[n] = cos(2\pi \omega_0 nT_e) + 4 sin(2\pi \omega_1 nT_e) + 2 cos(2\pi \omega_2 nT_e) + 3 sin(2\pi \omega_2 nT_e) \).</p>
                            <p>We know already its Fourier representation, it is: \( X[k] = C_{k_0} + C_{-k_{0}} + i (S_{k_1}+S_{-k_{1}}) + C_{k_2} + iS_{k_2} + C_{-k_{2}} + iS_{-k_{2}} \), with \( S_{-k_n} = -S_{k_n} \) and \( \omega_n = 2\pi\frac{k_n}{NT_e} \).</p>
                            <p>We can now apply the IFFT but only over <span class="bold">positive frequencies</span> to retrieve the analytic signal: \( x_a[n] = 2 (C_{k_0} e^{i\omega_0 n} + iS_{k_1} e^{i\omega_1 n} + C_{k_2} e^{i\omega_2 n} + iS_{k_2} e^{i\omega_2 n} ) = x[n] + i \mathcal{H}(x[n]) \).</p>
                            <p>Note that if we take only the <span class="bold">real part</span> (band-base) of this signal, we end up with the <span class="bold">real signal</span> \(x[n]\).
                                Also, the conservation of the complex form with the Fourier transform in the time domain is great because now the signal carries all the <span class="bold">necessary information</span> to compute useful <span class="bold">instantenous</span>
                                (i.e., at a particular moment \(t_0=n_0T_e\) in time) properties of the signal because it includes both <span class="bold">sinus and cosinus correlations</span>.
                                In fact, at each time index \(n\), we can compute the <span class="bold">instantaneous amplitude</span> and <span class="bold">phase</span> of the signal.
                                Moreover, the Fourier transform of this signal is much more convenient to work with because it has only <span class="bold">positive frequencies</span>.
                            </p>
                        </div>
                        <p>To summarize, we use the <span class="bold">Fourier analysis</span> to extract properties of a signal that are <span class="bold">not blatant</span> when considered in its time representation.
                            Then, we keep these newly acquired informations (frequencies contributions and phases) by <span class="bold">preserving the complex nature</span> of the signal. This allows to carry more information because the analytic signal has one more dimension (imaginary axis).
                            To preserve this complex nature we only need to operate the IFFT over the <span class="bold">positive frequencies</span> and <span class="bold">double their contribution</span> to account for the loss of negative frequencies (i.e., energy conservation).
                            By doing so, we don't lose any signal's information because all the necessary information is contained in the positive frequencies. 
                        </p>
                        <img src="images/signal/X[k]_complex_illustration.drawio.png" alt="">
                    </div>
                </div>
            </div>

            <div id="laplace"> <h2>Laplace: beyond the Fourier transform</h2>
                <p>In this section, I would like to expand on the Laplace transform; its mathematical meaning as well as its usual applications.</p>
                <p>As indicated in this section's title, the <span class="bold">Laplace transform</span> is an <span class="bold">generalization</span> of the Fourier transform. It means that it can describe and analyse a <span class="bold">wider range</span> of signals.
                    Indeed, the Fourier transform is limited to describing a signal <span class="bold">only</span> by using its frequency components (the operation involves a scalar product between the signal and the complex unit circle (cf <a href="#hilbert">here</a>)).
                    It helps us in vizualizing clearly the presence and contribution of each frequency in the signal.
                    With the <span class="bold">Laplace transform</span>, a new parameter \(\alpha\) is added, which accounts for a <span class="bold">scaling factor</span> in the complex exponential domain.
                    Thus, besides providing us information about the frequency components of the signal, it also gives us information about the <span class="bold">amplitude dynamics</span> of the signal.
                    In summary, it identifies the <span class="bold">presence of decreasing or increasing oscillations</span> in the signal.

                </p>
                <div> <h4>The Z-transform</h4>
                    <p>The Z-transform is simply the Laplace transform applied to <span class="bold">discrete signals</span>:
                        \[ X(p) = \int_{0}^{\infty} x(nT_e) e^{-pt}dt
                                = \int_{0}^{\infty} \sum_{n=0}^{\infty} x(nT_e) \delta(t-nT_e) e^{-pt}dt
                                = \sum_{n=0}^{\infty} x(nT_e) e^{-pnT_e}
                                \equiv X(z) = \sum_{n=0}^{\infty} x[n] z^{-n} \]
                        where \(z\) is a <span class="bold">complex number</span> and can be re-written like this: \(z=e^{pT_e}=e^{(\alpha+i\omega)T_e}=e^{\alpha T_e} e^{i\omega T_e}\).
                    </p>
                    <p>What we obtain is a <span class="bold">2D complex vector</span> \(X(z)\), where each \(z\) represents a specific <span class="bold">scaling factor</span> \(\alpha\) associated with a <span class="bold">frequency component</span> \(\omega\).</p>
                    <div class="frame-highlight">
                        <p>Note that with \(\alpha=0\), we get back to the Fourier transform \(z=e^{i\omega T_e}=e^{i 2\pi \nu T_e}\), which makes sense because this means no scaling factor in the signal and only <span class="bold">constant oscillations</span> (what the FT measures).</p>
                    </div>
                </div>
                <div> <h4>Applications</h4>
                    <p>This transform is particularly relevant when it comes to determining the <span class="bold">stability</span> of a system. A system whose impulse response outputs a signal with <span class="bold">increasing oscillations</span> \(\alpha > 0\) is <span class="bold">unstable</span>.
                        This can also be pictured in the complex exponential plane, where the <span class="bold">poles</span> of the system are located. If the poles are located in the <span class="bold">right half-plane</span> \(\alpha > 0\), the system is unstable. 
                    </p>
                    <div class="frame-highlight">
                        <p>The formula shown above clearly demonstrates that the sampling period \(T_e\) has an impact on the scaling of the system's reponse.
                            Indeed, the <span class="bold">smaller</span> the sampling period, the <span class="bold">slower</span> the amplitude dynamics \(e^{(\alpha T_e)}\).
                            <!-- This is why the <span class="bold">sampling frequency</span> is a <span class="bold">critical parameter</span> in the design of a system. -->
                        </p>
                    </div>
                    <p>It has also useful features that make it easy to resolve <span class="bold">linear differential equations</span>.</p>
                </div>
            </div>

            <div id="#wavelet"> <h2>Wavelet analysis</h2>
                <p>The Fourier transform is also quite limited because it assumes that a signal is <span class="bold">stationary</span>. It does not indicate where frequencies are located in time.
                    For that matter, we need to expand the Fourier transform to a 2D transform, where the second parameter would be the time delay \(\tau\).
                </p>
                <div> <h4>Short-Time Fourier transform</h4>
                    <p>This transform was thought up to temporally identify frequencies in a signal. Unlike the Fourier transform, here we restrain the identification of frequencies within a <span class="bold">window function</span>.
                        We slide this function over the signal and perform for each delay \(\tau\) a localized Fourier transform. The formula is defined as follows: 
                        \[ X(\tau, \omega) = \int^{+\infty}_{-\infty} x(t)w(t-\tau)e^{i\omega t} dt \]
                        where \(w(t-\tau)\) is a <span class="bold">window function</span> that is applied to the signal \(x(t)\) to <span class="bold">localize</span> the frequencies in time.
                        However, this technique has a limitation because the size of the window does not change with the frequency tested.
                        We know that higher frequencies need <span class="bold">high time resolution</span> because they last short (i.e., it takes little time to identify them properly), which also means <span class="bold">low frequency resolution</span>.
                        On the other hand, lower frequencies need <span class="bold">low time resolution</span> because they last long (i.e., it takes time to identify them properly), which also means <span class="bold">high frequency resolution</span>.
                        Considering what I just brought up, we need to adjust the <span class="bold">size of the window</span> according to the frequency tested. This will be the goal of the <span class="bold">Wavelets transform</span>.
                    </p>
                    <div class="frame-highlight">
                        <p>Note that the truncature of the signal with the window function has <span class="bold">consequences</span> in the spectrum density. Indeed, jitters can appear depending on the type of window.
                            Therefore, the type of truncature should be wisely chosen according to our goals. <a href="https://en.wikipedia.org/wiki/Window_function">Here</a> is a wide selection of window functions to chose from.
                            This is explained by the <span class="bold">Heisenberg uncertainty principle</span> which states that we cannot have a <span class="bold">perfect time and frequency resolution</span> at the same time.
                        </p>
                    </div>
                </div>
                <div> <h4>Wavelets transform</h4>
                    <p>The <span class="bold">Wavelets transform</span> follows up the STFT but adjusts the time (i.e., frequency) resolution accordingly. It is defined as follows:
                        \[ X(\tau, s) = \frac{1}{\sqrt{s}} \int^{+\infty}_{-\infty} x(t)\psi^{*}(\frac{t-\tau}{s}) dt \]
                        where \(\psi^{*}(\frac{t-\tau}{s})\) is the <span class="bold">mother wavelet</span>. \(s\) is the <span class="bold">scale</span> parameter that adjusts the size of the window according to the frequency tested.
                        \(\tau\) is the <span class="bold">time delay</span> parameter that slides the window over the signal.
                    </p>
                    <div class="frame-highlight">
                        <p>A wavelet must verify <span class="bold">two conditions</span>:</p>
                        <ul>
                            <p><li>It does not have an <span class="bold">offset</span> value: \( \int^{+\infty}_{-\infty} \psi^{*}(t) dt = 0 \).</li></p>
                            <p><li>It has a <span class="bold">finite energy</span>: \( \int^{+\infty}_{-\infty} |\psi^{*}(t)|^2 dt < \infty \).</li></p>
                        </ul>
                    </div>
                    <p>A <span class="bold">wavelet</span> is nothing more than a sine wave damped by a gaussian curve \( \psi^{*}(t) = k e^{i\omega t} e^{-\frac{t^2}{2}} \), where \( \omega\) is the wavelet's pulsation.</p>
                    <p></p>
                </div>
            </div>

        </section> <!-- main-container -->

        <div id="footer"></div>

    </body>

</html>